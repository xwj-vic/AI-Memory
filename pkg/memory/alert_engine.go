package memory

import (
	"ai-memory/pkg/logger"
	"ai-memory/pkg/store"
	"context"
	"encoding/json"
	"fmt"
	"sync"
	"time"

	"github.com/google/uuid"
)

// AlertLevel å‘Šè­¦çº§åˆ«
type AlertLevel string

const (
	AlertLevelInfo    AlertLevel = "INFO"
	AlertLevelWarning AlertLevel = "WARNING"
	AlertLevelError   AlertLevel = "ERROR"
)

// Alert å‘Šè­¦äº‹ä»¶
type Alert struct {
	ID        string                 `json:"id"`
	Level     AlertLevel             `json:"level"`
	Rule      string                 `json:"rule"`
	Message   string                 `json:"message"`
	Timestamp time.Time              `json:"timestamp"`
	Metadata  map[string]interface{} `json:"metadata"`
}

// AlertRule å‘Šè­¦è§„åˆ™
type AlertRule struct {
	ID          string
	Name        string
	Description string
	CheckFunc   func(ctx context.Context, metrics *MetricsCollector, stagingStore *store.StagingStore) *Alert
	Enabled     bool
	Cooldown    time.Duration

	// å¹¶å‘å®‰å…¨çš„çŠ¶æ€ç®¡ç†
	mu        sync.Mutex
	lastFired time.Time
}

// ShouldFire æ£€æŸ¥æ˜¯å¦åº”è¯¥è§¦å‘å‘Šè­¦ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
func (r *AlertRule) ShouldFire() bool {
	r.mu.Lock()
	defer r.mu.Unlock()
	return time.Since(r.lastFired) >= r.Cooldown
}

// MarkFired æ ‡è®°å‘Šè­¦å·²è§¦å‘ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
func (r *AlertRule) MarkFired() {
	r.mu.Lock()
	defer r.mu.Unlock()
	r.lastFired = time.Now()
}

// AlertEngine å‘Šè­¦å¼•æ“
type AlertEngine struct {
	mu               sync.RWMutex
	rules            []*AlertRule
	recentAlerts     []Alert // å†…å­˜çƒ­ç¼“å­˜ï¼ˆåªè¯»ï¼‰
	maxRecentAlerts  int
	checkInterval    time.Duration
	notifyFunc       func(alert *Alert)
	metricsCollector *MetricsCollector
	stagingStore     *store.StagingStore
	stopChan         chan struct{}

	// å­˜å‚¨å±‚ï¼ˆä¾èµ–æ³¨å…¥ï¼‰
	repository AlertRepository

	// ç¼“å­˜å‘Šè­¦æ™ºèƒ½åŒ–é…ç½®
	cacheCheckConfig *CacheCheckConfig

	// ç»Ÿè®¡ä¿¡æ¯
	stats *AlertEngineStats

	// è§„åˆ™é…ç½®æŒä¹…åŒ–
	configPersistence *RuleConfigPersistence

	// ç»Ÿè®¡ä¿¡æ¯ç¼“å­˜
	statsCache *StatsCache

	// ç»Ÿè®¡æ•°æ®æŒä¹…åŒ–
	statsPersistence *AlertStatsPersistence

	// ç»Ÿè®¡åŒæ­¥ç®¡ç†å™¨
	statsSync *AlertEngineStatsSync
}

// AlertEngineStats å‘Šè­¦å¼•æ“ç»Ÿè®¡
type AlertEngineStats struct {
	mu            sync.RWMutex
	TotalChecks   int64
	TotalFired    int64
	NotifySuccess int64
	NotifyFailed  int64
	RuleStats     map[string]*RuleStats
}

// RuleStats è§„åˆ™ç»Ÿè®¡
type RuleStats struct {
	mu               sync.RWMutex
	TotalFired       int64
	LastFiredAt      time.Time
	TotalChecks      int64
	AvgCheckDuration time.Duration
}

// CacheCheckConfig ç¼“å­˜å‘Šè­¦æ™ºèƒ½æ£€æµ‹é…ç½®
type CacheCheckConfig struct {
	WindowMinutes  int     // ç»Ÿè®¡çª—å£ï¼ˆåˆ†é’Ÿï¼‰
	MinSamples     int     // æœ€å°æ ·æœ¬æ•°
	WarnThreshold  float64 // è­¦å‘Šé˜ˆå€¼ï¼ˆç™¾åˆ†æ¯”ï¼‰
	ErrorThreshold float64 // é”™è¯¯é˜ˆå€¼ï¼ˆç™¾åˆ†æ¯”ï¼‰
	TrendPeriods   int     // è¶‹åŠ¿æ£€æµ‹å‘¨æœŸæ•°
}

// AlertConfig å‘Šè­¦å¼•æ“é…ç½®
type AlertConfig struct {
	CheckIntervalMinutes        int
	QueueBacklogThreshold       int
	QueueBacklogCooldownMinutes int
	SuccessRateThreshold        float64
	SuccessRateCooldownMinutes  int
	CacheHitRateThreshold       float64
	CacheHitRateCooldownMinutes int
	DecaySpikeThreshold         int
	DecaySpikeCooldownMinutes   int
	HistoryMaxSize              int

	// æ™ºèƒ½ç¼“å­˜æ£€æµ‹é…ç½®
	CacheWindowMinutes  int
	CacheMinSamples     int
	CacheWarnThreshold  float64
	CacheErrorThreshold float64
	CacheTrendPeriods   int
}

// NewAlertEngine åˆ›å»ºå‘Šè­¦å¼•æ“
func NewAlertEngine(repository AlertRepository, collector *MetricsCollector, stagingStore *store.StagingStore, config *AlertConfig) *AlertEngine {
	engine := &AlertEngine{
		rules:            make([]*AlertRule, 0),
		recentAlerts:     make([]Alert, 0, config.HistoryMaxSize),
		maxRecentAlerts:  config.HistoryMaxSize,
		checkInterval:    time.Duration(config.CheckIntervalMinutes) * time.Minute,
		metricsCollector: collector,
		stagingStore:     stagingStore,
		stopChan:         make(chan struct{}),
		repository:       repository,
		cacheCheckConfig: &CacheCheckConfig{
			WindowMinutes:  config.CacheWindowMinutes,
			MinSamples:     config.CacheMinSamples,
			WarnThreshold:  config.CacheWarnThreshold,
			ErrorThreshold: config.CacheErrorThreshold,
			TrendPeriods:   config.CacheTrendPeriods,
		},
	}

	// åˆå§‹åŒ–ç»Ÿè®¡
	engine.stats = &AlertEngineStats{
		RuleStats: make(map[string]*RuleStats),
	}

	// åˆå§‹åŒ–ç»Ÿè®¡ç¼“å­˜ï¼ˆ30ç§’TTLï¼‰
	engine.statsCache = NewStatsCache(30 * time.Second)

	// æ³¨å†Œé»˜è®¤è§„åˆ™
	engine.registerDefaultRules(config)

	return engine
}

// registerDefaultRules æ³¨å†Œé»˜è®¤å‘Šè­¦è§„åˆ™
func (ae *AlertEngine) registerDefaultRules(config *AlertConfig) {
	// è§„åˆ™1: é˜Ÿåˆ—ç§¯å‹å‘Šè­¦
	ae.AddRule(&AlertRule{
		ID:          "queue_backlog",
		Name:        "é˜Ÿåˆ—ç§¯å‹å‘Šè­¦",
		Description: "Stagingé˜Ÿåˆ—é•¿åº¦è¶…è¿‡é˜ˆå€¼",
		CheckFunc:   ae.makeQueueBacklogCheck(config.QueueBacklogThreshold),
		Enabled:     true,
		Cooldown:    time.Duration(config.QueueBacklogCooldownMinutes) * time.Minute,
	})

	// è§„åˆ™2: æ™‹å‡æˆåŠŸç‡ä¸‹é™
	ae.AddRule(&AlertRule{
		ID:          "low_success_rate",
		Name:        "æ™‹å‡æˆåŠŸç‡è¿‡ä½",
		Description: "æ™‹å‡æˆåŠŸç‡ä½äºé˜ˆå€¼",
		CheckFunc:   ae.makeLowSuccessRateCheck(config.SuccessRateThreshold),
		Enabled:     true,
		Cooldown:    time.Duration(config.SuccessRateCooldownMinutes) * time.Minute,
	})

	// è§„åˆ™3: ç¼“å­˜å¼‚å¸¸ï¼ˆæ™ºèƒ½æ£€æµ‹ï¼‰
	ae.AddRule(&AlertRule{
		ID:          "cache_anomaly",
		Name:        "ç¼“å­˜å‘½ä¸­ç‡å¼‚å¸¸",
		Description: "ç¼“å­˜å‘½ä¸­ç‡å¼‚å¸¸ä½æˆ–çªé™",
		CheckFunc:   ae.makeCacheAnomalyCheckSmart(), // ä½¿ç”¨æ™ºèƒ½æ£€æµ‹
		Enabled:     true,
		Cooldown:    time.Duration(config.CacheHitRateCooldownMinutes) * time.Minute,
	})

	// è§„åˆ™4: è®°å¿†è¡°å‡å¼‚å¸¸
	ae.AddRule(&AlertRule{
		ID:          "decay_spike",
		Name:        "è®°å¿†è¡°å‡çªå¢",
		Description: "é—å¿˜æ•°é‡çªå¢",
		CheckFunc:   ae.makeDecaySpikeCheck(config.DecaySpikeThreshold),
		Enabled:     true,
		Cooldown:    time.Duration(config.DecaySpikeCooldownMinutes) * time.Minute,
	})
}

// AddRule æ·»åŠ è‡ªå®šä¹‰è§„åˆ™
func (ae *AlertEngine) AddRule(rule *AlertRule) {
	ae.mu.Lock()
	defer ae.mu.Unlock()
	ae.rules = append(ae.rules, rule)
}

// Start å¯åŠ¨å‘Šè­¦å¼•æ“
func (ae *AlertEngine) Start(ctx context.Context) {
	ticker := time.NewTicker(ae.checkInterval)
	go func() {
		for {
			select {
			case <-ticker.C:
				ae.checkAllRules(ctx)
			case <-ae.stopChan:
				ticker.Stop()
				logger.System("Alert engine stopped")
				return
			}
		}
	}()

	logger.System("âœ… Alert engine started", "interval", ae.checkInterval, "rules", len(ae.rules))
}

// Stop åœæ­¢å‘Šè­¦å¼•æ“
func (ae *AlertEngine) Stop() {
	// åœæ­¢ç»Ÿè®¡åŒæ­¥ï¼ˆä¼šè‡ªåŠ¨åˆ·æ–°ï¼‰
	if ae.statsSync != nil {
		ae.statsSync.Stop()
	}
	close(ae.stopChan)
}

// checkAllRules æ£€æŸ¥æ‰€æœ‰è§„åˆ™
func (ae *AlertEngine) checkAllRules(ctx context.Context) {
	ae.mu.RLock()
	rules := make([]*AlertRule, len(ae.rules))
	copy(rules, ae.rules)
	ae.mu.RUnlock()

	// æ³¨æ„ï¼šTotalChecks ä¼šåœ¨æ¯ä¸ªè§„åˆ™çš„ recordRuleCheck ä¸­ç´¯ç§¯
	// ä¸åœ¨è¿™é‡Œé‡å¤ç»Ÿè®¡

	for _, rule := range rules {
		if !rule.Enabled {
			continue
		}

		// ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„å†·å´æ£€æŸ¥
		if !rule.ShouldFire() {
			continue
		}

		// è®°å½•æ‰§è¡Œæ—¶é—´
		startTime := time.Now()

		// æ‰§è¡Œè§„åˆ™æ£€æŸ¥
		alert := rule.CheckFunc(ctx, ae.metricsCollector, ae.stagingStore)

		duration := time.Since(startTime)
		ae.recordRuleCheck(rule.ID, duration) // è¿™é‡Œä¼šç´¯ç§¯TotalChecks

		if alert != nil {
			ae.fireAlert(ctx, alert)
			ae.recordRuleFire(rule.ID)
			rule.MarkFired()
		}
	}
}

// fireAlert è§¦å‘å‘Šè­¦
func (ae *AlertEngine) fireAlert(ctx context.Context, alert *Alert) {
	ae.mu.Lock()
	defer ae.mu.Unlock()

	// å‘Šè­¦èšåˆ
	aggregateAlert(alert)

	// æ·»åŠ åˆ°å†…å­˜çƒ­ç¼“å­˜
	ae.recentAlerts = append(ae.recentAlerts, *alert)
	if len(ae.recentAlerts) > ae.maxRecentAlerts {
		ae.recentAlerts = ae.recentAlerts[len(ae.recentAlerts)-ae.maxRecentAlerts:]
	}

	// æ—¥å¿—è®°å½•
	logger.System("ğŸš¨ ALERT FIRED",
		"id", alert.ID,
		"level", alert.Level,
		"rule", alert.Rule,
		"message", alert.Message,
		"timestamp", alert.Timestamp)

	// æŒä¹…åŒ–åˆ°æ•°æ®åº“ï¼ˆé€šè¿‡å­˜å‚¨å±‚ï¼‰
	if ae.repository != nil {
		if err := ae.repository.Save(ctx, alert); err != nil {
			logger.Error("Failed to persist alert", err)
			ae.recordNotifyResult(false)
		} else {
			ae.recordNotifyResult(true)
			// ä½¿ç»Ÿè®¡ç¼“å­˜å¤±æ•ˆ
			ae.InvalidateStatsCache()
		}
	}

	// è°ƒç”¨é€šçŸ¥å‡½æ•°
	if ae.notifyFunc != nil {
		go func() {
			defer func() {
				if r := recover(); r != nil {
					logger.Error("Panic in notify function", fmt.Errorf("%v", r))
					ae.recordNotifyResult(false)
				}
			}()
			ae.notifyFunc(alert)
			ae.recordNotifyResult(true)
		}()
	}
}

// SetNotifyFunc è®¾ç½®é€šçŸ¥å›è°ƒå‡½æ•°
func (ae *AlertEngine) SetNotifyFunc(f func(alert *Alert)) {
	ae.mu.Lock()
	defer ae.mu.Unlock()
	ae.notifyFunc = f
}

// GetRecentAlerts è·å–æœ€è¿‘çš„å‘Šè­¦è®°å½•ï¼ˆä»å†…å­˜çƒ­ç¼“å­˜ï¼‰
func (ae *AlertEngine) GetRecentAlerts(limit int) []Alert {
	ae.mu.RLock()
	defer ae.mu.RUnlock()

	if limit <= 0 || limit > len(ae.recentAlerts) {
		limit = len(ae.recentAlerts)
	}

	// è¿”å›æœ€è¿‘çš„Næ¡ï¼ˆå€’åºï¼‰
	result := make([]Alert, limit)
	start := len(ae.recentAlerts) - limit
	copy(result, ae.recentAlerts[start:])

	// åè½¬é¡ºåºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
	for i := 0; i < len(result)/2; i++ {
		j := len(result) - 1 - i
		result[i], result[j] = result[j], result[i]
	}

	return result
}

// QueryAlerts æŸ¥è¯¢å‘Šè­¦ï¼ˆå®Œæ•´æ•°æ®åº“æŸ¥è¯¢ï¼‰
func (ae *AlertEngine) QueryAlerts(ctx context.Context, level, rule string, limit, offset int) ([]Alert, int, error) {
	if ae.repository == nil {
		return nil, 0, fmt.Errorf("alert repository not initialized")
	}
	return ae.repository.QueryFiltered(ctx, level, rule, limit, offset)
}

// DeleteAlert åˆ é™¤å‘Šè­¦
func (ae *AlertEngine) DeleteAlert(ctx context.Context, id string) error {
	// ä»æ•°æ®åº“åˆ é™¤
	if ae.repository != nil {
		if err := ae.repository.Delete(ctx, id); err != nil {
			return err
		}
	}

	// ä»å†…å­˜ç¼“å­˜åˆ é™¤
	ae.mu.Lock()
	defer ae.mu.Unlock()
	newAlerts := make([]Alert, 0, len(ae.recentAlerts))
	for _, a := range ae.recentAlerts {
		if a.ID != id {
			newAlerts = append(newAlerts, a)
		}
	}
	ae.recentAlerts = newAlerts
	return nil
}

// CreateAlert æ‰‹åŠ¨åˆ›å»ºå‘Šè­¦
func (ae *AlertEngine) CreateAlert(ctx context.Context, alert Alert) error {
	if alert.Timestamp.IsZero() {
		alert.Timestamp = time.Now()
	}
	ae.fireAlert(ctx, &alert)
	return nil
}

// ========== å‘Šè­¦è§„åˆ™å®ç°ï¼ˆä½¿ç”¨é—­åŒ…æ”¯æŒé…ç½®åŒ–ï¼‰==========

// makeQueueBacklogCheck åˆ›å»ºé˜Ÿåˆ—ç§¯å‹æ£€æŸ¥å‡½æ•°ï¼ˆåŠ¨æ€è¯»å–é…ç½®ï¼‰
func (ae *AlertEngine) makeQueueBacklogCheck(defaultThreshold int) func(ctx context.Context, metrics *MetricsCollector, stagingStore *store.StagingStore) *Alert {
	return func(ctx context.Context, metrics *MetricsCollector, stagingStore *store.StagingStore) *Alert {
		// åŠ¨æ€è¯»å–é˜ˆå€¼é…ç½®
		threshold := defaultThreshold
		if ae.configPersistence != nil {
			configs, err := ae.configPersistence.LoadAll(ctx)
			if err == nil {
				if config, ok := configs["queue_backlog"]; ok && config.ConfigJSON != "" {
					var jsonConfig map[string]interface{}
					if json.Unmarshal([]byte(config.ConfigJSON), &jsonConfig) == nil {
						if t, ok := jsonConfig["threshold"].(float64); ok {
							threshold = int(t)
						}
					}
				}
			}
		}

		entries, err := stagingStore.GetPendingEntries(ctx, 1, 0)
		if err != nil {
			return nil
		}

		queueLength := len(entries)
		if queueLength > threshold {
			return &Alert{
				ID:        fmt.Sprintf("queue_backlog_%s", uuid.New().String()[:8]),
				Level:     AlertLevelWarning,
				Rule:      "queue_backlog",
				Message:   "Stagingé˜Ÿåˆ—ç§¯å‹è¿‡å¤šï¼Œè¯·æ£€æŸ¥æ™‹å‡é€»è¾‘",
				Timestamp: time.Now(),
				Metadata: map[string]interface{}{
					"queue_length": queueLength,
					"threshold":    threshold,
				},
			}
		}

		return nil
	}
}

// makeLowSuccessRateCheck åˆ›å»ºæˆåŠŸç‡æ£€æŸ¥å‡½æ•°
func (ae *AlertEngine) makeLowSuccessRateCheck(threshold float64) func(ctx context.Context, metrics *MetricsCollector, stagingStore *store.StagingStore) *Alert {
	return func(ctx context.Context, metrics *MetricsCollector, stagingStore *store.StagingStore) *Alert {
		metrics.mu.RLock()
		totalAttempts := metrics.TotalPromotions + metrics.TotalRejections
		promotions := metrics.TotalPromotions
		metrics.mu.RUnlock()

		if totalAttempts < 10 {
			return nil // æ ·æœ¬å¤ªå°‘ï¼Œä¸å‘Šè­¦
		}

		successRate := float64(promotions) / float64(totalAttempts) * 100
		if successRate < threshold {
			return &Alert{
				ID:        fmt.Sprintf("low_success_rate_%s", uuid.New().String()[:8]),
				Level:     AlertLevelWarning,
				Rule:      "low_success_rate",
				Message:   "è®°å¿†æ™‹å‡æˆåŠŸç‡è¿‡ä½ï¼Œå¯èƒ½æ˜¯åˆ¤å®šæ ‡å‡†è¿‡ä¸¥",
				Timestamp: time.Now(),
				Metadata: map[string]interface{}{
					"success_rate": successRate,
					"threshold":    threshold,
					"attempts":     totalAttempts,
				},
			}
		}

		return nil
	}
}

// makeCacheAnomalyCheckSmart åˆ›å»ºæ™ºèƒ½ç¼“å­˜å¼‚å¸¸æ£€æŸ¥å‡½æ•°
func (ae *AlertEngine) makeCacheAnomalyCheckSmart() func(ctx context.Context, metrics *MetricsCollector, stagingStore *store.StagingStore) *Alert {
	// å­˜å‚¨å†å²å‘½ä¸­ç‡ï¼ˆç”¨äºè¶‹åŠ¿æ£€æµ‹ï¼‰
	var historyRates []float64
	var historyMu sync.Mutex

	return func(ctx context.Context, metrics *MetricsCollector, stagingStore *store.StagingStore) *Alert {
		metrics.mu.RLock()
		totalAccess := metrics.CacheHits + metrics.CacheMisses
		hits := metrics.CacheHits
		metrics.mu.RUnlock()

		// æ£€æŸ¥1: æœ€å°æ ·æœ¬æ•°ï¼ˆé¿å…å†·å¯åŠ¨å’Œä½æµé‡è¯¯æŠ¥ï¼‰
		if totalAccess < int64(ae.cacheCheckConfig.MinSamples) {
			return nil
		}

		// è®¡ç®—å½“å‰å‘½ä¸­ç‡
		currentRate := float64(hits) / float64(totalAccess) * 100

		// æ£€æŸ¥2: åˆ†æ®µé˜ˆå€¼æ£€æµ‹
		var level AlertLevel
		var triggered bool

		if currentRate < ae.cacheCheckConfig.ErrorThreshold {
			level = AlertLevelError
			triggered = true
		} else if currentRate < ae.cacheCheckConfig.WarnThreshold {
			level = AlertLevelWarning
			triggered = true
		}

		// æ£€æŸ¥3: è¶‹åŠ¿æ£€æµ‹ï¼ˆçªé™æ£€æµ‹ï¼‰
		historyMu.Lock()
		historyRates = append(historyRates, currentRate)
		if len(historyRates) > ae.cacheCheckConfig.TrendPeriods {
			historyRates = historyRates[1:]
		}

		// å¦‚æœå†å²æ•°æ®è¶³å¤Ÿï¼Œæ£€æŸ¥æ˜¯å¦çªé™
		trendAlert := false
		if len(historyRates) >= ae.cacheCheckConfig.TrendPeriods {
			// è®¡ç®—å†å²å¹³å‡å€¼
			var sum float64
			for i := 0; i < len(historyRates)-1; i++ {
				sum += historyRates[i]
			}
			avgRate := sum / float64(len(historyRates)-1)

			// å¦‚æœå½“å‰å€¼æ¯”å¹³å‡å€¼ä½20%ä»¥ä¸Šï¼Œè§†ä¸ºçªé™
			if avgRate-currentRate > 20.0 {
				trendAlert = true
				triggered = true
				if level == "" {
					level = AlertLevelWarning
				}
			}
		}
		historyMu.Unlock()

		// è§¦å‘å‘Šè­¦
		if triggered {
			message := "ç¼“å­˜å‘½ä¸­ç‡å¼‚å¸¸ä½"
			if trendAlert {
				message = "ç¼“å­˜å‘½ä¸­ç‡çªé™ï¼Œå¯èƒ½LLMåˆ¤å®šé€»è¾‘æ•…éšœ"
			}

			return &Alert{
				ID:        fmt.Sprintf("cache_anomaly_%s", uuid.New().String()[:8]),
				Level:     level,
				Rule:      "cache_anomaly",
				Message:   message,
				Timestamp: time.Now(),
				Metadata: map[string]interface{}{
					"hit_rate":        currentRate,
					"warn_threshold":  ae.cacheCheckConfig.WarnThreshold,
					"error_threshold": ae.cacheCheckConfig.ErrorThreshold,
					"total_access":    totalAccess,
					"trend_detected":  trendAlert,
				},
			}
		}

		return nil
	}
}

// makeDecaySpikeCheck åˆ›å»ºè¡°å‡çªå¢æ£€æŸ¥å‡½æ•°
func (ae *AlertEngine) makeDecaySpikeCheck(threshold int) func(ctx context.Context, metrics *MetricsCollector, stagingStore *store.StagingStore) *Alert {
	return func(ctx context.Context, metrics *MetricsCollector, stagingStore *store.StagingStore) *Alert {
		metrics.mu.RLock()
		forgotten := metrics.TotalForgotten
		metrics.mu.RUnlock()

		if forgotten > int64(threshold) {
			return &Alert{
				ID:        fmt.Sprintf("decay_spike_%s", uuid.New().String()[:8]),
				Level:     AlertLevelInfo,
				Rule:      "decay_spike",
				Message:   "è®°å¿†é—å¿˜æ•°é‡è¾ƒé«˜ï¼Œè¿™å¯èƒ½æ˜¯æ­£å¸¸çš„è¡°å‡",
				Timestamp: time.Now(),
				Metadata: map[string]interface{}{
					"forgotten": forgotten,
					"threshold": threshold,
				},
			}
		}

		return nil
	}
}
